{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 6\n",
        "\n",
        "Adam Grabowski |\n",
        "CS 541 Deep Learning |\n",
        "November 6, 2023"
      ],
      "metadata": {
        "id": "1Luu86mVa1Zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1"
      ],
      "metadata": {
        "id": "BqbLw5QcB5qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "UqAlN_BaFV8o"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "    # Compute dot product between query and transposed key\n",
        "    dot_product = np.matmul(query, key.transpose(0, 2, 1))\n",
        "\n",
        "    # Scale dot product by square root of key's dimension\n",
        "    scaled_dot_product = dot_product / np.sqrt(key.shape[-1])\n",
        "\n",
        "    # Apply softmax to obtain attention scores\n",
        "    attention_scores = np.exp(scaled_dot_product - np.max(scaled_dot_product, axis=-1, keepdims=True))\n",
        "    attention_scores /= np.sum(attention_scores, axis=-1, keepdims=True)\n",
        "\n",
        "    # Weight values by attention scores to get output\n",
        "    output = np.matmul(attention_scores, value)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "1K51O7U7Jnj7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dimensions of input data\n",
        "batch_size = 2\n",
        "input_seq_length = 3\n",
        "query_dim = 4\n",
        "key_dim = 4\n",
        "value_dim = 5\n",
        "\n",
        "# Generate random input data for query, key, and value\n",
        "query = np.random.rand(batch_size, input_seq_length, query_dim)\n",
        "key = np.random.rand(batch_size, input_seq_length, key_dim)\n",
        "value = np.random.rand(batch_size, input_seq_length, value_dim)\n",
        "\n",
        "# Apply scaled dot-product attention mechanism\n",
        "output = scaled_dot_product_attention(query, key, value)\n",
        "\n",
        "# Print shape of output\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciu4avJVKRJy",
        "outputId": "ee2d6284-1f43-4d45-fd7b-440a1f9bc7d2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (2, 3, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_heads(x, num_heads):\n",
        "    # Get dimensions of input tensor\n",
        "    batch_size, input_seq_length, concatenated_dim = x.shape\n",
        "\n",
        "    # Calculate dimension of each head\n",
        "    head_dim = concatenated_dim // num_heads\n",
        "\n",
        "    # Reshape input tensor to split last dimension into multiple heads\n",
        "    x = x.reshape(batch_size, input_seq_length, num_heads, head_dim)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "KtcUdhr9LO6t"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dimensions for input data\n",
        "batch_size = 2\n",
        "input_seq_length = 3\n",
        "num_heads = 2\n",
        "concatenated_dim = 8\n",
        "\n",
        "# Generate random input data with specified dimensions\n",
        "x = np.random.rand(batch_size, input_seq_length, num_heads * concatenated_dim)\n",
        "\n",
        "# Apply split_heads function to split last dimension into multiple heads\n",
        "split_result = split_heads(x, num_heads)\n",
        "\n",
        "# Print shape of resulting tensor after splitting\n",
        "print(\"Split result shape:\", split_result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3SAq0wfLYmp",
        "outputId": "e0ddfdc4-af93-4c54-ff2d-edfb8af548ad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split result shape: (2, 3, 2, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_head_scaled_attention(query, key, value, num_heads, Wq, Wk, Wv):\n",
        "    # Project input tensors using learnable weight matrices\n",
        "    projected_query = np.matmul(query, Wq)\n",
        "    projected_key = np.matmul(key, Wk)\n",
        "    projected_value = np.matmul(value, Wv)\n",
        "\n",
        "    # Split each projected tensor into multiple heads\n",
        "    projected_query = split_heads(projected_query, num_heads)\n",
        "    projected_key = split_heads(projected_key, num_heads)\n",
        "    projected_value = split_heads(projected_value, num_heads)\n",
        "\n",
        "    # List to store outputs from each head\n",
        "    head_outputs = []\n",
        "\n",
        "    # Apply scaled dot-product attention for each head\n",
        "    for i in range(num_heads):\n",
        "        head_output = scaled_dot_product_attention(projected_query[:, :, i, :], projected_key[:, :, i, :], projected_value[:, :, i, :])\n",
        "        head_outputs.append(head_output)\n",
        "\n",
        "    # Concatenate outputs from all heads along last dimension\n",
        "    multi_head_output = np.concatenate(head_outputs, axis=-1)\n",
        "\n",
        "    return multi_head_output"
      ],
      "metadata": {
        "id": "nMhwelQbL-Aw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dimensions for input data\n",
        "batch_size = 2\n",
        "input_seq_length = 3\n",
        "query_dim = 4\n",
        "key_dim = 4\n",
        "value_dim = 5\n",
        "num_heads = 2\n",
        "\n",
        "# Generate random input data for query, key, and value\n",
        "query = np.random.rand(batch_size, input_seq_length, query_dim)\n",
        "key = np.random.rand(batch_size, input_seq_length, key_dim)\n",
        "value = np.random.rand(batch_size, input_seq_length, value_dim)\n",
        "\n",
        "# Generate random learnable weight matrices for projection\n",
        "Wq = np.random.rand(query_dim, num_heads * query_dim)\n",
        "Wk = np.random.rand(key_dim, num_heads * key_dim)\n",
        "Wv = np.random.rand(value_dim, num_heads * value_dim)\n",
        "\n",
        "# Apply multi-head scaled attention mechanism\n",
        "output = multi_head_scaled_attention(query, key, value, num_heads, Wq, Wk, Wv)\n",
        "\n",
        "# Print shape of resulting multi-head attention output\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uej9_BPMM4JR",
        "outputId": "d5afed3d-59e9-40fe-f697-1f19712ef4ea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (2, 3, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2"
      ],
      "metadata": {
        "id": "pCH4qjpkbUgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import torchtext.vocab as vocab\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "q74HF37Pa8Aj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define special tokens for start and end of scentence\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        # Language class to manage vocabulary\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        # Add each word in sentence to language vocabulary\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        # Add word to vocabulary not already present, update counts otherwise\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "lHoTwBklbcxq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    # Convert Unicode to ASCII characters\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    # Convert to ASCII, lowercase, and strip\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "\n",
        "    # Add space before punctuation and remove non-alphabetic characters\n",
        "    s = re.sub(r'([.!?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z!?]+', r' ', s)\n",
        "    return s.strip()"
      ],
      "metadata": {
        "id": "7lB6F3PPbjBi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    # Read lines from specified file and split into pairs\n",
        "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Normalize each pair of sentences\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # If reverse True, swap order of language pairs\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "RlVwnAdYboqe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum allowed length for sentence pairs\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "# French sentence prefixes to filter pairs\n",
        "fr_prefixes = (\n",
        "    \"je suis \", \"j'suis \",\n",
        "    \"il est \", \"il'st \",\n",
        "    \"elle est \", \"elle'st \",\n",
        "    \"tu es \", \"t'es \",\n",
        "    \"nous sommes \", \"nous'sommes \",\n",
        "    \"ils sont \", \"ils'sont \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    # Filter single sentence pair based on length and prefixes\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(fr_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    # Filter list of sentence pairs using filterPair\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "eCsfghfAbt2y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    # Create language objects and get pairs from file\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "\n",
        "    # Filter pairs based on length and prefixes\n",
        "    pairs = filterPairs(pairs)\n",
        "\n",
        "    # Add sentences from filtered pairs to language objects\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "# Prepare data for English to French translation\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra')"
      ],
      "metadata": {
        "id": "z8OdRHsEbwqd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define GRU layer and apply dropout to input\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Apply dropout to embedded input and pass it through GRU layer\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "2NVLh98pnoPL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # Define GRU layer and linear layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        # Loop over maximum sequence length\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            # Determine next decoder input\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        # Concatenate decoder outputs and apply log-softmax\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        # Apply embedding, ReLU, GRU, and linear layers\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "UsyMiU5ZcJhV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    # Convert sentence to indexes using language vocabulary\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    # Create tensor from sentence\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    # Create input and target tensors from sentence pair\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    # Prepare language data and pairs\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra')\n",
        "\n",
        "    # Initialize arrays for input and target sentence indices\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    # Convert sentences to indices and update arrays\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    input_ids_train, input_ids_test, target_ids_train, target_ids_test = train_test_split(\n",
        "        input_ids, target_ids, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create PyTorch datasets and data loaders\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids_train).to(device),\n",
        "                               torch.LongTensor(target_ids_train).to(device))\n",
        "    test_data = TensorDataset(torch.LongTensor(input_ids_test).to(device),\n",
        "                              torch.LongTensor(target_ids_test).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    # Return language objects and data loaders\n",
        "    return input_lang, output_lang, train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "FyXYQF-zcVv4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    # Initialize total loss for epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    # Iterate over batches in dataloader\n",
        "    for data in dataloader:\n",
        "        # Extract input and target tensors from batch\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        # Zero gradients of both encoder and decoder\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through encoder\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        # Forward pass through decoder\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        # Calculate loss and perform backpropagation\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Update encoder and decoder parameters\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "    # Return average loss for the epoch\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "a5tzcpUgce-j"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, encoder, decoder, criterion):\n",
        "    with torch.no_grad():\n",
        "        # Initialize total loss for evaluation\n",
        "        total_loss = 0\n",
        "\n",
        "        # Iterate over batches in dataloader\n",
        "        for data in dataloader:\n",
        "            # Extract input and target tensors from batch\n",
        "            input_tensor, target_tensor = data\n",
        "\n",
        "            # Forward pass through encoder\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "            # Forward pass through decoder\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            # Calculate loss and accumulate for evaluation\n",
        "            loss = criterion(\n",
        "                decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "                target_tensor.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    # Return average loss for evaluation\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "emWsrrgrc_6d"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        # Convert input sentence to PyTorch tensor\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        # Forward pass through encoder\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        # Forward pass through decoder\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        # Extract index with highest probability for each position\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        # Convert indices to words in output language\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            # Stop decoding when encounter EOS token\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "    return decoded_words"
      ],
      "metadata": {
        "id": "WJlq_bMYc9WB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, test_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=5):\n",
        "    # Lists to store training and test losses for each epoch\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    # Initialize Adam optimizers for encoder and decoder\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Define negative log likelihood loss criterion\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    # Iterate over epochs\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # Train model for one epoch and record training loss\n",
        "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Evaluate model on test set and record test loss\n",
        "        test_loss = evaluate(test_dataloader, encoder, decoder, criterion)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        # Print training and test losses for each epoch\n",
        "        print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "        # Print translation example every 5 epochs\n",
        "        if epoch % print_every == 0:\n",
        "            input_sentence = pairs[0][0]\n",
        "            output_words = translate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "            output_sentence = ' '.join(output_words)\n",
        "            print(f'Translation: {input_sentence} -> {output_sentence}')\n",
        "\n",
        "    return train_losses, test_losses"
      ],
      "metadata": {
        "id": "kyXLF-YFcpOh"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dimensions and batch size\n",
        "input_size = 100\n",
        "hidden_size = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Obtain language data and data loaders for training and testing\n",
        "input_lang, output_lang, train_dataloader, test_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "# Initialize Encoder and Decoder models\n",
        "encoder = EncoderRNN(input_size, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "# Load pre-trained GloVe word embeddings\n",
        "glove = vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "# Modify GloVe's vocabulary to include unknown token\n",
        "glove.itos = ['<unk>'] + glove.itos\n",
        "glove.stoi = {word: index for index, word in enumerate(glove.itos)}\n",
        "\n",
        "# Add zero vector for unknown token\n",
        "zero_vector = np.zeros((1, glove.vectors.shape[1]), dtype=np.float32)\n",
        "glove.vectors = torch.cat([torch.tensor(zero_vector), glove.vectors])\n",
        "\n",
        "# Create embedding layer from pre-trained vectors\n",
        "embedding = nn.Embedding.from_pretrained(glove.vectors).to(device)\n",
        "\n",
        "# Freeze embedding layer to keep pre-trained weights fixed\n",
        "embedding.weight.requires_grad = False\n",
        "encoder.embedding = embedding\n",
        "\n",
        "# Train sequence-to-sequence model for 80 epochs\n",
        "train_losses, test_losses = train(train_dataloader, test_dataloader, encoder, decoder, 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PRNqzqbdZFE",
        "outputId": "d961187d-d159-484f-9a9e-4cd4d6b3a0db"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 3.7513, Test Loss: 2.7930\n",
            "Epoch 2, Train Loss: 2.5720, Test Loss: 2.4746\n",
            "Epoch 3, Train Loss: 2.2656, Test Loss: 2.2725\n",
            "Epoch 4, Train Loss: 2.0484, Test Loss: 2.1408\n",
            "Epoch 5, Train Loss: 1.8944, Test Loss: 2.0559\n",
            "Translation: i fell -> je suis desole de vous avoir fait <EOS>\n",
            "Epoch 6, Train Loss: 1.7698, Test Loss: 1.9989\n",
            "Epoch 7, Train Loss: 1.6646, Test Loss: 1.9550\n",
            "Epoch 8, Train Loss: 1.5739, Test Loss: 1.9122\n",
            "Epoch 9, Train Loss: 1.4923, Test Loss: 1.8825\n",
            "Epoch 10, Train Loss: 1.4207, Test Loss: 1.8564\n",
            "Translation: i fell -> je suis alle a la plage <EOS>\n",
            "Epoch 11, Train Loss: 1.3548, Test Loss: 1.8378\n",
            "Epoch 12, Train Loss: 1.2956, Test Loss: 1.8242\n",
            "Epoch 13, Train Loss: 1.2415, Test Loss: 1.8103\n",
            "Epoch 14, Train Loss: 1.1942, Test Loss: 1.8064\n",
            "Epoch 15, Train Loss: 1.1463, Test Loss: 1.7963\n",
            "Translation: i fell -> je suis alle a la gare a la maison <EOS>\n",
            "Epoch 16, Train Loss: 1.1031, Test Loss: 1.7896\n",
            "Epoch 17, Train Loss: 1.0628, Test Loss: 1.7865\n",
            "Epoch 18, Train Loss: 1.0254, Test Loss: 1.7756\n",
            "Epoch 19, Train Loss: 0.9901, Test Loss: 1.7789\n",
            "Epoch 20, Train Loss: 0.9574, Test Loss: 1.7738\n",
            "Translation: i fell -> je suis alle a la gare a la maison <EOS>\n",
            "Epoch 21, Train Loss: 0.9260, Test Loss: 1.7741\n",
            "Epoch 22, Train Loss: 0.8964, Test Loss: 1.7677\n",
            "Epoch 23, Train Loss: 0.8690, Test Loss: 1.7681\n",
            "Epoch 24, Train Loss: 0.8426, Test Loss: 1.7744\n",
            "Epoch 25, Train Loss: 0.8180, Test Loss: 1.7671\n",
            "Translation: i fell -> je suis tombe sur un ami dans le bus <EOS>\n",
            "Epoch 26, Train Loss: 0.7925, Test Loss: 1.7718\n",
            "Epoch 27, Train Loss: 0.7704, Test Loss: 1.7724\n",
            "Epoch 28, Train Loss: 0.7489, Test Loss: 1.7727\n",
            "Epoch 29, Train Loss: 0.7289, Test Loss: 1.7710\n",
            "Epoch 30, Train Loss: 0.7078, Test Loss: 1.7776\n",
            "Translation: i fell -> je suis arrive ici a l ecole aujourd hui <EOS>\n",
            "Epoch 31, Train Loss: 0.6894, Test Loss: 1.7809\n",
            "Epoch 32, Train Loss: 0.6705, Test Loss: 1.7853\n",
            "Epoch 33, Train Loss: 0.6532, Test Loss: 1.7857\n",
            "Epoch 34, Train Loss: 0.6385, Test Loss: 1.7899\n",
            "Epoch 35, Train Loss: 0.6206, Test Loss: 1.7884\n",
            "Translation: i fell -> je suis reste a l interieur car il pleuvait <EOS>\n",
            "Epoch 36, Train Loss: 0.6055, Test Loss: 1.7954\n",
            "Epoch 37, Train Loss: 0.5909, Test Loss: 1.8036\n",
            "Epoch 38, Train Loss: 0.5772, Test Loss: 1.8074\n",
            "Epoch 39, Train Loss: 0.5654, Test Loss: 1.8055\n",
            "Epoch 40, Train Loss: 0.5491, Test Loss: 1.8112\n",
            "Translation: i fell -> je suis arrive ici a un probleme <EOS>\n",
            "Epoch 41, Train Loss: 0.5377, Test Loss: 1.8143\n",
            "Epoch 42, Train Loss: 0.5241, Test Loss: 1.8213\n",
            "Epoch 43, Train Loss: 0.5137, Test Loss: 1.8283\n",
            "Epoch 44, Train Loss: 0.5031, Test Loss: 1.8334\n",
            "Epoch 45, Train Loss: 0.4908, Test Loss: 1.8360\n",
            "Translation: i fell -> je suis arrive ici a heures environ <EOS>\n",
            "Epoch 46, Train Loss: 0.4806, Test Loss: 1.8423\n",
            "Epoch 47, Train Loss: 0.4688, Test Loss: 1.8537\n",
            "Epoch 48, Train Loss: 0.4608, Test Loss: 1.8539\n",
            "Epoch 49, Train Loss: 0.4519, Test Loss: 1.8602\n",
            "Epoch 50, Train Loss: 0.4426, Test Loss: 1.8670\n",
            "Translation: i fell -> je suis tombe amoureux de toi <EOS>\n",
            "Epoch 51, Train Loss: 0.4335, Test Loss: 1.8746\n",
            "Epoch 52, Train Loss: 0.4249, Test Loss: 1.8819\n",
            "Epoch 53, Train Loss: 0.4174, Test Loss: 1.8851\n",
            "Epoch 54, Train Loss: 0.4067, Test Loss: 1.8883\n",
            "Epoch 55, Train Loss: 0.4018, Test Loss: 1.8929\n",
            "Translation: i fell -> je suis tombe amoureux de la musique <EOS>\n",
            "Epoch 56, Train Loss: 0.3913, Test Loss: 1.9083\n",
            "Epoch 57, Train Loss: 0.3848, Test Loss: 1.9129\n",
            "Epoch 58, Train Loss: 0.3787, Test Loss: 1.9132\n",
            "Epoch 59, Train Loss: 0.3699, Test Loss: 1.9180\n",
            "Epoch 60, Train Loss: 0.3626, Test Loss: 1.9303\n",
            "Translation: i fell -> je suis parti en amerique maintenant <EOS>\n",
            "Epoch 61, Train Loss: 0.3577, Test Loss: 1.9313\n",
            "Epoch 62, Train Loss: 0.3519, Test Loss: 1.9502\n",
            "Epoch 63, Train Loss: 0.3457, Test Loss: 1.9508\n",
            "Epoch 64, Train Loss: 0.3386, Test Loss: 1.9581\n",
            "Epoch 65, Train Loss: 0.3305, Test Loss: 1.9584\n",
            "Translation: i fell -> je suis tombe amoureuse de la musique <EOS>\n",
            "Epoch 66, Train Loss: 0.3268, Test Loss: 1.9722\n",
            "Epoch 67, Train Loss: 0.3220, Test Loss: 1.9759\n",
            "Epoch 68, Train Loss: 0.3156, Test Loss: 1.9871\n",
            "Epoch 69, Train Loss: 0.3122, Test Loss: 1.9960\n",
            "Epoch 70, Train Loss: 0.3085, Test Loss: 1.9882\n",
            "Translation: i fell -> je suis tombe amoureuse de la musique <EOS>\n",
            "Epoch 71, Train Loss: 0.3019, Test Loss: 2.0002\n",
            "Epoch 72, Train Loss: 0.2971, Test Loss: 2.0032\n",
            "Epoch 73, Train Loss: 0.2907, Test Loss: 2.0155\n",
            "Epoch 74, Train Loss: 0.2869, Test Loss: 2.0156\n",
            "Epoch 75, Train Loss: 0.2812, Test Loss: 2.0296\n",
            "Translation: i fell -> je suis tombe amoureuse de toi <EOS>\n",
            "Epoch 76, Train Loss: 0.2763, Test Loss: 2.0370\n",
            "Epoch 77, Train Loss: 0.2742, Test Loss: 2.0346\n",
            "Epoch 78, Train Loss: 0.2696, Test Loss: 2.0496\n",
            "Epoch 79, Train Loss: 0.2663, Test Loss: 2.0504\n",
            "Epoch 80, Train Loss: 0.2622, Test Loss: 2.0578\n",
            "Translation: i fell -> je suis parti aussi tot que tom <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train and test losses over epochs\n",
        "plt.figure()\n",
        "plt.plot(train_losses, label='Train Loss', color='blue')\n",
        "plt.plot(test_losses, label='Test Loss', color='orange')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "I3aOHBeKipV4",
        "outputId": "75d606cd-d9e3-44b4-89a4-573807fe2b8c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7928fca96470>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}